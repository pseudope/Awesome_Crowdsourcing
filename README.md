# Awesome Crowdsourcing

This repository contains major crowdsourcing papers. (Last Update: 20230825) <br>
**Bold**: 100+ Cited

## Datasets

### Classification
|Dataset|Data Type|Classes|Annotators|Train Data|Val Data|Test Data|Link|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|LabelMe (Original)|Image|8|77|1,000|500|1,188|[Link](https://fprodrigues.com/publications/deep-crowds/)|
|LabelMe (Compressed)|Extracted from VGG-16|8|59|10,000|500|1,188|[Link](https://fprodrigues.com/publications/deep-crowds/)|
|Music|.csv File|10|44|700 (595)|- (105)|300|[Link](https://fprodrigues.com/publications/deep-crowds/)|
|CIFAR-10H|Image|10|2,571|10,000|-|-|[Link](https://github.com/jcpeterson/cifar-10h)|

### Regression


## By Years

### Survey
* [2016] A Survey on Truth Discovery <br>
  (Li et al.) [[Link](https://dl.acm.org/doi/abs/10.1145/2897350.2897352)]

### ~ 2017
* **[J. R. Stat. Soc., C: Appl. Stat. 1979] Maximum Likelihood Estimation of Observer Error-rates Using the EM Algorithm** <br>
  (Dawid and Skene) [Not Public]
* **[ICML 2011] Active learning from crowds** <br>
  (Yan et al.) [[Link](https://dl.acm.org/doi/10.5555/3104482.3104628)]
* **[AAAI 2014] Crowdsourcing for Multiple-Choice Question Answering** <br>
  (Aydin et al.) [[Link](https://aaai.org/papers/016-crowdsourcing-for-multiple-choice-question-answering/)]
* **[NeurIPS 2014 + JMLR 2016] Spectral Methods meet EM: A Provably Optimal Algorithm for Crowdsourcing** <br>
  (Zhang et al.) [[Link 1](https://proceedings.neurips.cc/paper/2014/hash/788d986905533aba051261497ecffcbb-Abstract.html)] [[Link 2](https://jmlr.org/papers/v17/14-511.html)]
* [ICML 2016] Optimality of Belief Propagation for Crowdsourced Classification <br>
  (Ok et al.) [[Link 1](https://proceedings.mlr.press/v48/ok16)] [[Link2](https://proceedings.mlr.press/v48/ok16)]
* [IJCAI 2017] Aggregating Crowd Wisdoms with Label-aware Autoencoders <br>
  (Yin et al.) [[Link](https://www.ijcai.org/proceedings/2017/0184)]
* **[VLDB 2017] Truth Inference in Crowdsourcing: Is the Problem Solved?** <br>
  (Zheng et al.) [[Link](https://dl.acm.org/doi/abs/10.14778/3055540.3055547)]

### 2018
* **[AAAI 2018] Deep Learning from Crowds** <br>
  (Rodrigues and Pereira) [[Link](https://arxiv.org/abs/1709.01779)]
* **[AAAI 2018] Who Said What: Modeling Individual Labelers Improves Classification** <br>
  (Guan et al.) [[Link](https://arxiv.org/abs/1703.08774)]
* **[ICLR 2018] Learning From Noisy Singly-labeled Data** <br>
  (Khetan et al.) [[Link](https://arxiv.org/abs/1712.04577)]
* [ICML 2018] Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers <br>
  (Ma et al.) [[Link](https://arxiv.org/abs/1904.11608)]
* [ICML 2018] Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model <br>
  (Imamura et al.) [[Link](https://arxiv.org/abs/1802.04551)]
* [WWW 2018] Leveraging Crowdsourcing Data For Deep Active Learning - An Application: Learning Intents in Alexa <br>
  (Yang et al.) [[Link](https://arxiv.org/abs/1803.04223)]

### 2019
* [ICLR 2019] Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds <br>
  (Cao et al.) [[Link](https://openreview.net/forum?id=BJg9DoR9t7)]
* [NeurIPS 2019] Crowdsourcing via Pairwise Co-occurrences: Identifiability and Algorithms <br>
  (Ibrahim et al.) [[Link](https://arxiv.org/abs/1909.12325)]
* **[CVPR 2019] Learning From Noisy Labels By Regularized Estimation of Annotator Confusion** <br>
  (Tanno et al.) [[Link](https://arxiv.org/abs/1902.03680)]
* **[ICCV 2019] Human Uncertainty Makes Classification More Robust** <br>
  (Peterson et al.) [[Link](https://arxiv.org/abs/1908.07086)]
* [ICML 2019] Exploiting Worker Correlation for Label Aggregation in Crowdsourcing <br>
  (Li et al.) [[Link](https://proceedings.mlr.press/v97/li19i.html)]


### 2020
* [NeurIPS 2020] Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion <br>
  (Ma and Olshevsky) [[Link](https://arxiv.org/abs/2010.12181)]
* [VLDM 2020] Detecting and Preventing Confused Labels in Crowdsourced Data <br>
  (Krivosheev et al.) [[Link](http://www.vldb.org/pvldb/vol13/p2522-krivosheev.pdf)]

### 2021
* [AAAI 2021] Learning from Crowds by Modeling Common Confusions <br>
  (Chu et al.) [[Link](https://arxiv.org/abs/2012.13052)]
* [KDD 2021] Improve Learning from Crowds via Generative Augmentation <br>
  (Chu and Wang) [[Link](https://arxiv.org/abs/2107.10449)]
* [NeurIPS 2021] End-to-End Weak Supervision <br>
  (Cachay et al.) [[Link](https://arxiv.org/abs/2107.02233)]

### 2022
* [AAAI 2022] Adversarial Learning from Crowds <br>
  (Chen et al.) [[Link](https://ojs.aaai.org/index.php/AAAI/article/view/20467)]
* [AAAI 2022] Robust Deep Learning from Crowds with Belief Propagation <br>
  (Kim, Cho et al.) [[Link](https://arxiv.org/abs/2111.00734)]
* [ICLR 2022 Oral] PiCO: Contrastive Label Disambiguation for Partial Label Learning <br>
  (Wang et al.) [[Link](https://openreview.net/forum?id=EhYjZy6e1gJ)] [[Link for PiCO+](https://arxiv.org/abs/2201.08984)]
* [ECCV 2022] Learning from Multiple Annotator Noisy Labels via Sample-Wise Label Fusion <br>
  (Gao et al.) [[Link](https://link.springer.com/chapter/10.1007/978-3-031-20053-3_24)]
* [TNNLS 2022] Deep Learning From Multiple Noisy Annotators as A Union <br>
  (Wei et al.) [[Link](https://ieeexplore.ieee.org/abstract/document/9765651)]
* [NeurIPS 2022 W] CROWDLAB: Supervised learning to infer consensus labels and quality scores for data with multiple annotators <br>
  (Goh et al.) [[Link](https://arxiv.org/abs/2210.06812)]
* [AAAI HCOMP 2022] Eliciting and Learning with Soft Labels from Every Annotator <br>
  (Collins et al.) [[Link](https://ojs.aaai.org/index.php/HCOMP/article/view/21986)]

### 2023
* [AAAI 2023] Losses over Labels: Weakly Supervised Learning via Direct Loss Construction <br>
  (Sam and Kolter) [[Link](https://ojs.aaai.org/index.php/AAAI/article/view/26159)]
* [AAAI 2023] Learning with Partial Labels from Semi-supervised Perspective <br>
  (Xu et al.) [[Link](https://arxiv.org/abs/2211.13655)]
* [ICLR 2023] Deep Learning From Crowdsourced Labels: Coupled Cross-entropy Minimization, Identifiability, and Regularization <br>
  (Ibrahim et al.) [[Link](https://arxiv.org/abs/2306.03288)]
* [ICLR 2023] Learning Hyper Label Model for Programmatic Weak Supervision <br>
  (Wu et al.) [[Link](https://openreview.net/forum?id=aCQt_BrkSjC)]
* [ICML 2023] Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing <br>
  (Jeong and Chung) [[Link](https://arxiv.org/abs/2301.00006)]
* [ICML 2023] FREDIS: A Fusion Framework of Refinement and Disambiguation for Unreliable Partial Label Learning <br>
  (Qiao et al.) [[Link](https://proceedings.mlr.press/v202/qiao23b.html)]
* [SIGIR 2023] Learning from Crowds with Annotation Reliability <br>
  (Cao et al.) [[Link](https://dl.acm.org/doi/abs/10.1145/3539618.3592007)]
* [IJCAI 2023] TDG4Crowd:Test Data Generation for Evaluation of Aggregation Algorithms in Crowdsourcing <br>
  (Fang et al.) [[Link](https://www.ijcai.org/proceedings/2023/0333)]
* [TMLR 2023 (Under Review)] Multi-annotator Deep Learning: A Probabilistic Framework for Classification <br>
  (Anonymous) [[Link](https://openreview.net/forum?id=MgdoxzImlK&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR))]

## By Topics
TBA
